{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e497677-7bc8-4a76-8a8a-18c589d496bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T05:39:52.114181Z",
     "iopub.status.busy": "2022-07-25T05:39:52.113630Z",
     "iopub.status.idle": "2022-07-25T05:39:52.119153Z",
     "shell.execute_reply": "2022-07-25T05:39:52.118491Z",
     "shell.execute_reply.started": "2022-07-25T05:39:52.114155Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/work\n"
     ]
    }
   ],
   "source": [
    "# cd to your workstation, if necessary\n",
    "%cd /home/aistudio/work/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f65ed18-cc85-46b8-843f-8cf2543c4382",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T05:39:52.122208Z",
     "iopub.status.busy": "2022-07-25T05:39:52.121644Z",
     "iopub.status.idle": "2022-07-25T05:39:57.080679Z",
     "shell.execute_reply": "2022-07-25T05:39:57.079591Z",
     "shell.execute_reply.started": "2022-07-25T05:39:52.122185Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_table('train.csv', sep='\\t')\n",
    "test = pd.read_table('test.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af09e425-3382-44d1-a546-54dfc55ec761",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T05:39:57.082533Z",
     "iopub.status.busy": "2022-07-25T05:39:57.081890Z",
     "iopub.status.idle": "2022-07-25T05:39:57.087172Z",
     "shell.execute_reply": "2022-07-25T05:39:57.086487Z",
     "shell.execute_reply.started": "2022-07-25T05:39:57.082502Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test = test.loc[:0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1626f8ca-576b-4518-bd73-b9959af93139",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T05:39:57.088727Z",
     "iopub.status.busy": "2022-07-25T05:39:57.088123Z",
     "iopub.status.idle": "2022-07-25T05:39:58.350541Z",
     "shell.execute_reply": "2022-07-25T05:39:58.349307Z",
     "shell.execute_reply.started": "2022-07-25T05:39:57.088702Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 导入所需的第三方库\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import collections\n",
    "from functools import partial\n",
    "import random\n",
    "import time\n",
    "import inspect\n",
    "import importlib\n",
    "from tqdm import tqdm\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "import paddle.nn.functional as F\n",
    "from paddle.io import IterableDataset\n",
    "from paddle.utils.download import get_path_from_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20a5408-af62-4c10-a243-c71690ce944b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T05:39:58.352783Z",
     "iopub.status.busy": "2022-07-25T05:39:58.352062Z",
     "iopub.status.idle": "2022-07-25T05:40:09.188029Z",
     "shell.execute_reply": "2022-07-25T05:40:09.186922Z",
     "shell.execute_reply.started": "2022-07-25T05:39:58.352742Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade paddlenlp==2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34242600-c16a-4a76-82b3-edae5e4b5829",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T05:40:09.190028Z",
     "iopub.status.busy": "2022-07-25T05:40:09.189379Z",
     "iopub.status.idle": "2022-07-25T05:40:09.591701Z",
     "shell.execute_reply": "2022-07-25T05:40:09.590651Z",
     "shell.execute_reply.started": "2022-07-25T05:40:09.189994Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 导入paddlenlp所需的相关包\n",
    "import paddlenlp as ppnlp\n",
    "from paddlenlp.data import JiebaTokenizer, Pad, Stack, Tuple, Vocab\n",
    "from paddlenlp.datasets import MapDataset\n",
    "from paddle.dataset.common import md5file\n",
    "from paddlenlp.datasets import DatasetBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4543a93c-fd28-4c1d-ad6f-6f8991e3dd36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T05:40:09.593978Z",
     "iopub.status.busy": "2022-07-25T05:40:09.593224Z",
     "iopub.status.idle": "2022-07-25T05:40:43.119250Z",
     "shell.execute_reply": "2022-07-25T05:40:43.118369Z",
     "shell.execute_reply.started": "2022-07-25T05:40:09.593935Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 使用roberta-wwm-ext-large模型\n",
    "# MODEL_NAME = \"roberta-wwm-ext-large\"\n",
    "# 从保存的参数中读取\n",
    "MODEL_NAME = 'test_0.83_finished'\n",
    "# 只需指定想要使用的模型名称和文本分类的类别数即可完成Fine-tune网络定义，通过在预训练模型后拼接上一个全连接网络（Full Connected）进行分类\n",
    "model = ppnlp.transformers.RobertaForSequenceClassification.from_pretrained(MODEL_NAME, num_classes=8) # 此次分类任务为8分类任务，故num_classes设置为8\n",
    "# 定义模型对应的tokenizer，tokenizer可以把原始输入文本转化成模型model可接受的输入数据格式。需注意tokenizer类要与选择的模型相对应，具体可以查看PaddleNLP相关文档\n",
    "tokenizer = ppnlp.transformers.RobertaTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16aa382e-d3d0-4a80-992d-08d4320ae0fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T05:40:43.120773Z",
     "iopub.status.busy": "2022-07-25T05:40:43.120402Z",
     "iopub.status.idle": "2022-07-25T05:40:43.128033Z",
     "shell.execute_reply": "2022-07-25T05:40:43.127368Z",
     "shell.execute_reply.started": "2022-07-25T05:40:43.120747Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 定义数据加载和处理函数\n",
    "def convert_example(example, tokenizer, max_seq_length=128, is_test=False):\n",
    "    qtconcat = example[\"text_a\"]\n",
    "    encoded_inputs = tokenizer(text=qtconcat, max_seq_len=max_seq_length)  # tokenizer处理为模型可接受的格式 \n",
    "    input_ids = encoded_inputs[\"input_ids\"]\n",
    "    token_type_ids = encoded_inputs[\"token_type_ids\"]\n",
    "\n",
    "    if not is_test:\n",
    "        label = np.array([example[\"label\"]], dtype=\"int64\")\n",
    "        return input_ids, token_type_ids, label\n",
    "    else:\n",
    "        return input_ids, token_type_ids\n",
    "\n",
    "# 定义数据加载函数dataloader\n",
    "def create_dataloader(dataset,\n",
    "                      mode='train',\n",
    "                      batch_size=1,\n",
    "                      batchify_fn=None,\n",
    "                      trans_fn=None):\n",
    "    if trans_fn:\n",
    "        dataset = dataset.map(trans_fn)\n",
    "\n",
    "    shuffle = True if mode == 'train' else False\n",
    "    # 训练数据集随机打乱，测试数据集不打乱\n",
    "    if mode == 'train':\n",
    "        batch_sampler = paddle.io.DistributedBatchSampler(\n",
    "            dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    else:\n",
    "        batch_sampler = paddle.io.BatchSampler(\n",
    "            dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "    return paddle.io.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_sampler=batch_sampler,\n",
    "        collate_fn=batchify_fn,\n",
    "        return_list=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d08d65fc-d826-4df4-b628-e23b0a7b02a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T05:49:31.921420Z",
     "iopub.status.busy": "2022-07-25T05:49:31.920760Z",
     "iopub.status.idle": "2022-07-25T05:49:31.930925Z",
     "shell.execute_reply": "2022-07-25T05:49:31.930006Z",
     "shell.execute_reply.started": "2022-07-25T05:49:31.921388Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义模型预测函数\n",
    "@paddle.no_grad()\n",
    "def predict(model, data, tokenizer, label_map, batch_size=1):\n",
    "    examples = []\n",
    "    # 将输入数据（list格式）处理为模型可接受的格式\n",
    "    for text in data:\n",
    "        input_ids, segment_ids = convert_example(\n",
    "            text,\n",
    "            tokenizer,\n",
    "            max_seq_length=256,\n",
    "            is_test=True)\n",
    "        examples.append((input_ids, segment_ids))\n",
    "\n",
    "    batchify_fn = lambda samples, fn=Tuple(\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_id),  # input id\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_id),  # segment id\n",
    "    ): fn(samples)\n",
    "\n",
    "    # Seperates data into some batches.\n",
    "    batches = []\n",
    "    one_batch = []\n",
    "    for example in examples:\n",
    "        one_batch.append(example)\n",
    "        if len(one_batch) == batch_size:\n",
    "            batches.append(one_batch)\n",
    "            one_batch = []\n",
    "    if one_batch:\n",
    "        # The last batch whose size is less than the config batch_size setting.\n",
    "        batches.append(one_batch)\n",
    "\n",
    "    results = []\n",
    "    model.eval()\n",
    "    for batch in batches:\n",
    "        input_ids, segment_ids = batchify_fn(batch)\n",
    "        input_ids = paddle.to_tensor(input_ids)\n",
    "        segment_ids = paddle.to_tensor(segment_ids)\n",
    "        logits = model(input_ids, segment_ids)\n",
    "        probs = F.softmax(logits, axis=1)\n",
    "        idx = paddle.argmax(probs, axis=1).numpy()\n",
    "        idx = idx.tolist()\n",
    "        labels = [label_map[i] for i in idx]\n",
    "        results.extend(labels)\n",
    "    return results  # 返回预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0b1cce-442d-4db4-8a70-d103dbae246e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T05:49:31.933108Z",
     "iopub.status.busy": "2022-07-25T05:49:31.932515Z",
     "iopub.status.idle": "2022-07-25T05:49:31.954389Z",
     "shell.execute_reply": "2022-07-25T05:49:31.953477Z",
     "shell.execute_reply.started": "2022-07-25T05:49:31.933080Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 定义要进行分类的类别\n",
    "label_list=list(train.label.unique())\n",
    "label_map = { \n",
    "    idx: label_text for idx, label_text in enumerate(label_list)\n",
    "}\n",
    "print(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5d5f048a-7bb1-45d6-9797-4c1367255daf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T05:57:15.401484Z",
     "iopub.status.busy": "2022-07-25T05:57:15.400067Z",
     "iopub.status.idle": "2022-07-25T05:57:15.407528Z",
     "shell.execute_reply": "2022-07-25T05:57:15.406561Z",
     "shell.execute_reply.started": "2022-07-25T05:57:15.401436Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义对数据的预处理函数,处理为模型输入指定list格式\n",
    "def preprocess_prediction_data(data):\n",
    "    examples = []\n",
    "    for text_a in data:\n",
    "        examples.append({\"text_a\": text_a})\n",
    "    return examples\n",
    "\n",
    "# 对测试集数据进行格式处理\n",
    "data1 = list(test.text_a)\n",
    "examples = preprocess_prediction_data(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae5e718-9111-4094-b589-8ddbbfdc1b7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T05:57:15.410599Z",
     "iopub.status.busy": "2022-07-25T05:57:15.409778Z",
     "iopub.status.idle": "2022-07-25T05:57:17.273491Z",
     "shell.execute_reply": "2022-07-25T05:57:17.272229Z",
     "shell.execute_reply.started": "2022-07-25T05:57:15.410560Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 对测试集进行预测\n",
    "results = predict(model, examples, tokenizer, label_map, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592ca878-2987-478d-8d4d-7f0ae7d116b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T05:57:17.275015Z",
     "iopub.status.busy": "2022-07-25T05:57:17.274746Z",
     "iopub.status.idle": "2022-07-25T05:57:17.280457Z",
     "shell.execute_reply": "2022-07-25T05:57:17.279643Z",
     "shell.execute_reply.started": "2022-07-25T05:57:17.274992Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 将list格式的预测结果存储为txt文件，提交格式要求：每行一个类别\n",
    "def write_results(labels, file_path):\n",
    "    with open(file_path, \"w\", encoding=\"utf8\") as f:\n",
    "        f.writelines(\"\\n\".join(labels))\n",
    "\n",
    "write_results(results, \"./result.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
