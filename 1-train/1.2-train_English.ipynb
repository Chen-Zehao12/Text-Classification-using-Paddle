{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-30T06:32:37.264888Z",
     "iopub.status.busy": "2022-07-30T06:32:37.264210Z",
     "iopub.status.idle": "2022-07-30T06:32:37.270738Z",
     "shell.execute_reply": "2022-07-30T06:32:37.269979Z",
     "shell.execute_reply.started": "2022-07-30T06:32:37.264847Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cd to your workstation, if necessary\n",
    "%cd /home/aistudio/work/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-30T06:32:37.272681Z",
     "iopub.status.busy": "2022-07-30T06:32:37.272208Z",
     "iopub.status.idle": "2022-07-30T06:32:42.029857Z",
     "shell.execute_reply": "2022-07-30T06:32:42.028904Z",
     "shell.execute_reply.started": "2022-07-30T06:32:37.272654Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 使用pandas读取数据集\n",
    "import pandas as pd\n",
    "\n",
    "train = pd.read_table('data/English/train.csv', sep='\\t')  # 训练集\n",
    "test = pd.read_table('data/English/test.csv', sep='\\t')    # 测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-30T06:32:42.032210Z",
     "iopub.status.busy": "2022-07-30T06:32:42.031338Z",
     "iopub.status.idle": "2022-07-30T06:32:42.075765Z",
     "shell.execute_reply": "2022-07-30T06:32:42.074977Z",
     "shell.execute_reply.started": "2022-07-30T06:32:42.032164Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-30T06:32:42.077307Z",
     "iopub.status.busy": "2022-07-30T06:32:42.076963Z",
     "iopub.status.idle": "2022-07-30T06:32:44.036586Z",
     "shell.execute_reply": "2022-07-30T06:32:44.035477Z",
     "shell.execute_reply.started": "2022-07-30T06:32:42.077279Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 导入所需的第三方库\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import collections\n",
    "from functools import partial\n",
    "import random\n",
    "import time\n",
    "import inspect\n",
    "import importlib\n",
    "from tqdm import tqdm\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "import paddle.nn.functional as F\n",
    "from paddle.io import IterableDataset\n",
    "from paddle.utils.download import get_path_from_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-30T06:32:44.039664Z",
     "iopub.status.busy": "2022-07-30T06:32:44.038997Z",
     "iopub.status.idle": "2022-07-30T06:32:50.995807Z",
     "shell.execute_reply": "2022-07-30T06:32:50.994766Z",
     "shell.execute_reply.started": "2022-07-30T06:32:44.039630Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade paddlenlp==2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-30T06:32:50.998372Z",
     "iopub.status.busy": "2022-07-30T06:32:50.997557Z",
     "iopub.status.idle": "2022-07-30T06:32:51.440103Z",
     "shell.execute_reply": "2022-07-30T06:32:51.439228Z",
     "shell.execute_reply.started": "2022-07-30T06:32:50.998322Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 导入paddlenlp所需的相关包\n",
    "import paddlenlp as ppnlp\n",
    "from paddlenlp.data import JiebaTokenizer, Pad, Stack, Tuple, Vocab\n",
    "from paddlenlp.datasets import MapDataset\n",
    "from paddle.dataset.common import md5file\n",
    "from paddlenlp.datasets import DatasetBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-30T06:32:51.441876Z",
     "iopub.status.busy": "2022-07-30T06:32:51.441291Z",
     "iopub.status.idle": "2022-07-30T06:33:08.080598Z",
     "shell.execute_reply": "2022-07-30T06:33:08.079394Z",
     "shell.execute_reply.started": "2022-07-30T06:32:51.441834Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 使用ernie-2.0-large-en模型\n",
    "# MODEL_NAME_OR_PATH = \"ernie-2.0-large-en\"\n",
    "# 从保存的参数中读取\n",
    "MODEL_NAME_OR_PATH = 'English_0.82_finished'\n",
    "# 只需指定想要使用的模型名称和文本分类的类别数即可完成Fine-tune网络定义，通过在预训练模型后拼接上一个全连接网络（Full Connected）进行分类\n",
    "model = ppnlp.transformers.ErnieForSequenceClassification.from_pretrained(MODEL_NAME_OR_PATH, num_classes=8) # 此次分类任务为8分类任务，故num_classes设置为8\n",
    "# 定义模型对应的tokenizer，tokenizer可以把原始输入文本转化成模型model可接受的输入数据格式。需注意tokenizer类要与选择的模型相对应，具体可以查看PaddleNLP相关文档\n",
    "tokenizer = ppnlp.transformers.ErnieTokenizer.from_pretrained(MODEL_NAME_OR_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-30T06:33:08.082539Z",
     "iopub.status.busy": "2022-07-30T06:33:08.082082Z",
     "iopub.status.idle": "2022-07-30T06:33:08.104838Z",
     "shell.execute_reply": "2022-07-30T06:33:08.103959Z",
     "shell.execute_reply.started": "2022-07-30T06:33:08.082502Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义要进行分类的8个类别\n",
    "label_list=list(train.label.unique())\n",
    "print(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-30T06:33:08.106309Z",
     "iopub.status.busy": "2022-07-30T06:33:08.106062Z",
     "iopub.status.idle": "2022-07-30T06:33:08.115356Z",
     "shell.execute_reply": "2022-07-30T06:33:08.114478Z",
     "shell.execute_reply.started": "2022-07-30T06:33:08.106286Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 定义数据集对应文件及其文件存储格式\n",
    "class NewsData(DatasetBuilder):\n",
    "    SPLITS = {\n",
    "        'train': 'data/English/train.csv',  # 训练集\n",
    "        'dev': 'data/English/test.csv',      # 验证集\n",
    "    }\n",
    "\n",
    "    def _get_data(self, mode, **kwargs):\n",
    "        filename = self.SPLITS[mode]\n",
    "        return filename\n",
    "\n",
    "    def _read(self, filename):\n",
    "        \"\"\"读取数据\"\"\"\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            head = None\n",
    "            for line in f:\n",
    "                data = line.strip().split(\"\\t\")    # 以'\\t'分隔各列\n",
    "                if len(data) != 2:\n",
    "                    continue\n",
    "                if not head:\n",
    "                    head = data\n",
    "                else:\n",
    "                    try:\n",
    "                        text_a, label = data\n",
    "                        if len(label) != 1:\n",
    "                            continue\n",
    "                        yield {\"text_a\": text_a.lower(), \"label\": label}  # 此次设置数据的格式为：text_a,label，可以根据具体情况进行修改\n",
    "                    except:\n",
    "                        continue\n",
    "\n",
    "    def get_labels(self):\n",
    "        return label_list   # 类别标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-30T06:33:08.116732Z",
     "iopub.status.busy": "2022-07-30T06:33:08.116400Z",
     "iopub.status.idle": "2022-07-30T06:33:08.121831Z",
     "shell.execute_reply": "2022-07-30T06:33:08.120957Z",
     "shell.execute_reply.started": "2022-07-30T06:33:08.116697Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 定义数据集加载函数\n",
    "def load_dataset(name=None,\n",
    "                 data_files=None,\n",
    "                 splits=None,\n",
    "                 lazy=None,\n",
    "                 **kwargs):\n",
    "   \n",
    "    reader_cls = NewsData  # 加载定义的数据集格式\n",
    "    print(reader_cls)\n",
    "    if not name:\n",
    "        reader_instance = reader_cls(lazy=lazy, **kwargs)\n",
    "    else:\n",
    "        reader_instance = reader_cls(lazy=lazy, name=name, **kwargs)\n",
    "\n",
    "    datasets = reader_instance.read_datasets(data_files=data_files, splits=splits)\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-30T06:33:08.123200Z",
     "iopub.status.busy": "2022-07-30T06:33:08.122895Z",
     "iopub.status.idle": "2022-07-30T06:33:11.032854Z",
     "shell.execute_reply": "2022-07-30T06:33:11.031836Z",
     "shell.execute_reply.started": "2022-07-30T06:33:08.123176Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 加载训练和验证集\n",
    "train_ds, dev_ds = load_dataset(splits=[\"train\", \"dev\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-30T06:33:11.034444Z",
     "iopub.status.busy": "2022-07-30T06:33:11.034051Z",
     "iopub.status.idle": "2022-07-30T06:33:11.041689Z",
     "shell.execute_reply": "2022-07-30T06:33:11.040984Z",
     "shell.execute_reply.started": "2022-07-30T06:33:11.034415Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 定义数据加载和处理函数\n",
    "def convert_example(example, tokenizer, max_seq_length=128, is_test=False):\n",
    "    qtconcat = example[\"text_a\"]\n",
    "    encoded_inputs = tokenizer(text=qtconcat, max_seq_len=max_seq_length)  # tokenizer处理为模型可接受的格式 \n",
    "    input_ids = encoded_inputs[\"input_ids\"]\n",
    "    token_type_ids = encoded_inputs[\"token_type_ids\"]\n",
    "\n",
    "    if not is_test:\n",
    "        label = np.array([example[\"label\"]], dtype=\"int64\")\n",
    "        return input_ids, token_type_ids, label\n",
    "    else:\n",
    "        return input_ids, token_type_ids\n",
    "\n",
    "# 定义数据加载函数dataloader\n",
    "def create_dataloader(dataset,\n",
    "                      mode='train',\n",
    "                      batch_size=1,\n",
    "                      batchify_fn=None,\n",
    "                      trans_fn=None):\n",
    "    if trans_fn:\n",
    "        dataset = dataset.map(trans_fn)\n",
    "\n",
    "    shuffle = True if mode == 'train' else False\n",
    "    # 训练数据集随机打乱，测试数据集不打乱\n",
    "    if mode == 'train':\n",
    "        batch_sampler = paddle.io.DistributedBatchSampler(\n",
    "            dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    else:\n",
    "        batch_sampler = paddle.io.BatchSampler(\n",
    "            dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "    return paddle.io.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_sampler=batch_sampler,\n",
    "        collate_fn=batchify_fn,\n",
    "        return_list=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-30T06:33:11.045169Z",
     "iopub.status.busy": "2022-07-30T06:33:11.044776Z",
     "iopub.status.idle": "2022-07-30T06:33:11.048511Z",
     "shell.execute_reply": "2022-07-30T06:33:11.047846Z",
     "shell.execute_reply.started": "2022-07-30T06:33:11.045145Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 参数设置：\n",
    "# 批处理大小，显存如若不足的话可以适当改小该值  \n",
    "batch_size = 40\n",
    "# 文本序列最大截断长度，需要根据文本具体长度进行确定，最长不超过512。 \n",
    "max_seq_length = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-30T06:33:11.049658Z",
     "iopub.status.busy": "2022-07-30T06:33:11.049373Z",
     "iopub.status.idle": "2022-07-30T06:33:11.055332Z",
     "shell.execute_reply": "2022-07-30T06:33:11.054652Z",
     "shell.execute_reply.started": "2022-07-30T06:33:11.049636Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 将数据处理成模型可读入的数据格式\n",
    "trans_func = partial(\n",
    "    convert_example,\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_length=max_seq_length)\n",
    "\n",
    "batchify_fn = lambda samples, fn=Tuple(\n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_id),  # input_ids\n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_type_id),  # token_type_ids\n",
    "    Stack()  # labels\n",
    "): [data for data in fn(samples)]\n",
    "\n",
    "# 训练集迭代器\n",
    "train_data_loader = create_dataloader(\n",
    "    train_ds,\n",
    "    mode='train',\n",
    "    batch_size=batch_size,\n",
    "    batchify_fn=batchify_fn,\n",
    "    trans_fn=trans_func)\n",
    "\n",
    "# 验证集迭代器\n",
    "dev_data_loader = create_dataloader(\n",
    "    dev_ds,\n",
    "    mode='dev',\n",
    "    batch_size=batch_size,\n",
    "    batchify_fn=batchify_fn,\n",
    "    trans_fn=trans_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-30T06:33:11.056420Z",
     "iopub.status.busy": "2022-07-30T06:33:11.056105Z",
     "iopub.status.idle": "2022-07-30T06:33:11.064263Z",
     "shell.execute_reply": "2022-07-30T06:33:11.063594Z",
     "shell.execute_reply.started": "2022-07-30T06:33:11.056394Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 定义超参，loss，优化器等\n",
    "from paddlenlp.transformers import LinearDecayWithWarmup\n",
    "\n",
    "# 定义训练配置参数：\n",
    "# 定义训练过程中的最大学习率\n",
    "learning_rate = 4e-5\n",
    "# 训练轮次\n",
    "epochs = 1\n",
    "# 学习率预热比例\n",
    "warmup_proportion = 0.1\n",
    "# 权重衰减系数，类似模型正则项策略，避免模型过拟合\n",
    "weight_decay = 0.0\n",
    "\n",
    "num_training_steps = len(train_data_loader) * epochs\n",
    "lr_scheduler = LinearDecayWithWarmup(learning_rate, num_training_steps, warmup_proportion)\n",
    "\n",
    "# AdamW优化器\n",
    "optimizer = paddle.optimizer.AdamW(\n",
    "    learning_rate=lr_scheduler,\n",
    "    parameters=model.parameters(),\n",
    "    weight_decay=weight_decay,\n",
    "    apply_decay_param_fun=lambda x: x in [\n",
    "        p.name for n, p in model.named_parameters()\n",
    "        if not any(nd in n for nd in [\"bias\", \"norm\"])\n",
    "    ])\n",
    "\n",
    "criterion = paddle.nn.loss.CrossEntropyLoss()  # 交叉熵损失函数\n",
    "metric = paddle.metric.Accuracy()              # accuracy评价指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-30T06:33:11.065381Z",
     "iopub.status.busy": "2022-07-30T06:33:11.065099Z",
     "iopub.status.idle": "2022-07-30T06:33:30.615531Z",
     "shell.execute_reply": "2022-07-30T06:33:30.614555Z",
     "shell.execute_reply.started": "2022-07-30T06:33:11.065359Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 加载学习器和优化器\n",
    "if os.path.isdir(MODEL_NAME_OR_PATH):\n",
    "    try:\n",
    "        lr_scheduler.set_state_dict(paddle.load(MODEL_NAME_OR_PATH + \"/lr\"))\n",
    "        optimizer.set_state_dict(paddle.load(MODEL_NAME_OR_PATH + \"/opt\"))\n",
    "\n",
    "        optimizer._learning_rate = 0.000010\n",
    "\n",
    "        print('Learning rate:', optimizer.get_lr())\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    print(\"Loaded parameters from %s\" % MODEL_NAME_OR_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-30T06:33:30.617330Z",
     "iopub.status.busy": "2022-07-30T06:33:30.616906Z",
     "iopub.status.idle": "2022-07-30T06:33:30.623663Z",
     "shell.execute_reply": "2022-07-30T06:33:30.622928Z",
     "shell.execute_reply.started": "2022-07-30T06:33:30.617299Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义模型训练验证评估函数\n",
    "@paddle.no_grad()\n",
    "def evaluate(model, criterion, metric, data_loader):\n",
    "    model.eval()\n",
    "    metric.reset()\n",
    "    losses = []\n",
    "    for batch in data_loader:\n",
    "        input_ids, token_type_ids, labels = batch\n",
    "        logits = model(input_ids, token_type_ids)\n",
    "        loss = criterion(logits, labels)\n",
    "        losses.append(loss.numpy())\n",
    "        correct = metric.compute(logits, labels)\n",
    "        metric.update(correct)\n",
    "        accu = metric.accumulate()\n",
    "    print(\"eval loss: %.5f, accu: %.5f\" % (np.mean(losses), accu))  # 输出验证集上评估效果\n",
    "    model.train()\n",
    "    metric.reset()\n",
    "    return accu  # 返回准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-30T06:33:30.624985Z",
     "iopub.status.busy": "2022-07-30T06:33:30.624616Z",
     "iopub.status.idle": "2022-07-30T06:33:30.628637Z",
     "shell.execute_reply": "2022-07-30T06:33:30.627934Z",
     "shell.execute_reply.started": "2022-07-30T06:33:30.624961Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # # 固定随机种子便于结果的复现\n",
    "# seed = 1024\n",
    "# random.seed(seed)\n",
    "# np.random.seed(seed)\n",
    "# paddle.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-30T06:33:30.629949Z",
     "iopub.status.busy": "2022-07-30T06:33:30.629558Z",
     "iopub.status.idle": "2022-07-30T11:44:48.667814Z",
     "shell.execute_reply": "2022-07-30T11:44:48.667036Z",
     "shell.execute_reply.started": "2022-07-30T06:33:30.629925Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 模型训练：\n",
    "import paddle.nn.functional as F\n",
    "\n",
    "save_dir = \"checkpoint\"\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "pre_accu=0\n",
    "accu=0\n",
    "global_step = 0\n",
    "for epoch in range(1, epochs + 1):\n",
    "    for step, batch in enumerate(train_data_loader, start=1):\n",
    "        input_ids, segment_ids, labels = batch\n",
    "        logits = model(input_ids, segment_ids)\n",
    "        loss = criterion(logits, labels)\n",
    "        probs = F.softmax(logits, axis=1)\n",
    "        correct = metric.compute(probs, labels)\n",
    "        metric.update(correct)\n",
    "        acc = metric.accumulate()\n",
    "\n",
    "        global_step += 1\n",
    "        if global_step % 10 == 0 :\n",
    "            print(\"global step %d, epoch: %d, batch: %d, loss: %.5f, acc: %.5f, lr: %f\" % (global_step, epoch, step, loss, acc, optimizer.get_lr()))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.clear_grad()\n",
    "\n",
    "    save_param_path = os.path.join(save_dir, 'model_state.pdparams')  # 保存模型参数\n",
    "    save_lr_path = os.path.join(save_dir, 'lr')\n",
    "    save_opt_path = os.path.join(save_dir, 'opt')\n",
    "\n",
    "    # paddle.save(model.state_dict(), save_param_path)\n",
    "    model.save_pretrained(save_dir)\n",
    "    paddle.save(lr_scheduler.state_dict(), save_lr_path)\n",
    "    paddle.save(optimizer.state_dict(), save_opt_path)\n",
    "    tokenizer.save_pretrained(save_dir)\n",
    "\n",
    "    accu = evaluate(model, criterion, metric, dev_data_loader)\n",
    "    print(accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-30T11:44:48.669511Z",
     "iopub.status.busy": "2022-07-30T11:44:48.668919Z",
     "iopub.status.idle": "2022-07-30T11:44:48.673615Z",
     "shell.execute_reply": "2022-07-30T11:44:48.672921Z",
     "shell.execute_reply.started": "2022-07-30T11:44:48.669482Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 保存label_map\n",
    "label_map = {}\n",
    "for idx, value in enumerate(label_list):\n",
    "    label_map[idx] = value\n",
    "\n",
    "with open(save_dir + '/label_map.json', 'w') as f:\n",
    "    json.dump(label_map, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
